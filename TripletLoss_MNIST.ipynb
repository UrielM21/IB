{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TripletLoss-MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UrielM21/IB/blob/main/TripletLoss_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGtGplbH1Xmv"
      },
      "source": [
        "# MNIST Digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3N6mv1c1Gs-"
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorboard.plugins import projector\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "SMALL_SIZE = 16\n",
        "MEDIUM_SIZE = 16\n",
        "BIGGER_SIZE = 18\n",
        "\n",
        "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
        "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
        "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
        "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
        "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
        "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
        "\n",
        "\n",
        "def images_to_sprite(data):\n",
        "    \"\"\"\n",
        "    Source : https://github.com/tensorflow/tensorflow/issues/6322\n",
        "    \"\"\"\n",
        "    if len(data.shape) == 3:\n",
        "        data = np.tile(data[..., np.newaxis], (1, 1, 1, 3))\n",
        "    data = data.astype(np.float32)\n",
        "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
        "    data = (data.transpose(1, 2, 3, 0) - min).transpose(3, 0, 1, 2)\n",
        "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
        "    data = (data.transpose(1, 2, 3, 0) / max).transpose(3, 0, 1, 2)\n",
        "\n",
        "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
        "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
        "               (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
        "    data = np.pad(data, padding, mode='constant',\n",
        "                  constant_values=0)\n",
        "    # Tile the individual thumbnails into an image.\n",
        "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
        "                                                           + tuple(range(4, data.ndim + 1)))\n",
        "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
        "    data = (data * 255).astype(np.uint8)\n",
        "    return data\n",
        "\n",
        "def prepare_for_visualization(embeddings, data_ds, name='test'):\n",
        "  images = np.concatenate([x[0] for x in data_ds.as_numpy_iterator()]) # Podria usar .unbatch tambien\n",
        "  images = normalize(images, scale=255, dtype=np.uint8)\n",
        "  images = np.squeeze(images)\n",
        "  images = resize(images, (images.shape[0], 64, 64, 3))\n",
        "\n",
        "  labels = np.concatenate([x[1] for x in data_ds.as_numpy_iterator()])\n",
        "  labels = [str(x) for x in labels]\n",
        "\n",
        "  sprite_name = name+'_sprite.png'\n",
        "  tensor_shape = list(embeddings.shape)\n",
        "  single_image_dim = [images.shape[1], images.shape[2]]\n",
        "  tensor_name = name+\"_embeddings.bytes\"\n",
        "  metadataPath = name+'_meta.tsv'\n",
        "\n",
        "  folder = 'oss_data/'\n",
        "  try:\n",
        "    os.mkdir(folder)\n",
        "  except FileExistsError:\n",
        "    pass\n",
        "  out_m = io.open(os.path.join(folder, metadataPath), 'w', encoding='utf-8')\n",
        "  # for img, labels in data_ds.as_numpy_iterator():\n",
        "  #     [out_m.write(str(x) + \"\\n\") for x in labels]\n",
        "  for label in labels:\n",
        "    out_m.write(label + \"\\n\")\n",
        "  out_m.close()\n",
        "\n",
        "  sprite = Image.fromarray(images_to_sprite(images).astype(np.uint8))\n",
        "  sprite.save(os.path.join(folder, sprite_name))\n",
        "  print(name+': ', sprite.size)\n",
        "\n",
        "  embeddings.tofile(os.path.join(folder, tensor_name))\n",
        "\n",
        "  oss_json = {'embeddings':[]}\n",
        "  json_to_append = {\"tensorName\": 'Visualization_'+name,\n",
        "                    \"tensorShape\": tensor_shape,\n",
        "                    \"tensorPath\": \"oss_data/\" + tensor_name,\n",
        "                    \"metadataPath\": \"oss_data/\" + metadataPath,\n",
        "                    \"sprite\": {\"imagePath\": \"oss_data/\" + sprite_name,\n",
        "                                \"singleImageDim\": single_image_dim}}\n",
        "  oss_json['embeddings'].append(json_to_append)\n",
        "  with open(os.path.join(folder, name+'_projector_config.json'), 'w+') as f:\n",
        "      json.dump(oss_json, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "def _normalize_img(img, label):\n",
        "    img = tf.cast(img, tf.float32) / 255.\n",
        "    return (img, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DOk3PMH1i4w"
      },
      "source": [
        "train_dataset, test_dataset = tfds.load(name=\"mnist\", split=['train', 'test'], as_supervised=True)\n",
        "\n",
        "# Build your input pipelines\n",
        "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
        "train_dataset = train_dataset.map(_normalize_img)\n",
        "\n",
        "test_dataset = test_dataset.batch(32)\n",
        "test_dataset = test_dataset.map(_normalize_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3AtSJtR1mK-"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=None), # No activation on final dense layer\n",
        "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
        "\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tfa.losses.TripletSemiHardLoss())\n",
        "\n",
        "# Train the network\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVWkxK5x1yId"
      },
      "source": [
        "# Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h5bCGl81ogn"
      },
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI2b2iFr1vad"
      },
      "source": [
        "# Prepare data for visualization in Tensorboard Projector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0pIIrRh1sAO"
      },
      "source": [
        "embeddings = model.predict(test_dataset)\n",
        "prepare_for_visualization(embeddings, test_dataset, name='test')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}